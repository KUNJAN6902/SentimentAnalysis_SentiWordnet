{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentimentAnalysis_SentiWordnet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wl6c-Xah9gcO",
        "colab_type": "text"
      },
      "source": [
        "#**Importing Required Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhNeppG6Eo9B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "f9749cdc-3bb7-4879-c63c-0b03e4e72c8f"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.corpus import sentiwordnet as swn\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('sentiwordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "sentence = \"One of the best movie of all time. Period.\""
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package sentiwordnet to /root/nltk_data...\n",
            "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dh7FuMaLAqb2",
        "colab_type": "text"
      },
      "source": [
        "#**Text PreProcessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Qz5iqQpoYVn",
        "colab_type": "text"
      },
      "source": [
        "####(1) Removing Punctuations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiF5qTEU8eI3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9c337c56-8564-4db4-df98-b34434a19fe5"
      },
      "source": [
        "punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "\n",
        "for x in sentence: \n",
        "  if x in punctuations: \n",
        "    sentence = sentence.replace(x, \"\")\n",
        "\n",
        "print(sentence)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "One of the best movie of all time Period\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E162bD8uohb1",
        "colab_type": "text"
      },
      "source": [
        "####(2) Change Case + Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKVrpopOEp3h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fa0a915b-6876-4798-f6d6-78b25b38d0a1"
      },
      "source": [
        "Tokens = nltk.word_tokenize(sentence.lower())\n",
        "print(Tokens)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['one', 'of', 'the', 'best', 'movie', 'of', 'all', 'time', 'period']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juVoKR1JooNE",
        "colab_type": "text"
      },
      "source": [
        "####(3) Removing Stop Words - a, an, the, are, is etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3DgjGz9FgT_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d00c0d6-9757-4046-c0e1-fe0bf9376100"
      },
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "clean_Tokens = [word for word in Tokens if word not in stop_words]\n",
        "print(clean_Tokens)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['one', 'best', 'movie', 'time', 'period']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTbjBljvosx8",
        "colab_type": "text"
      },
      "source": [
        "####(4) Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjItEe7DszZI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5db4bff3-0759-4e00-80f6-e80b7af12503"
      },
      "source": [
        "lemma = [lemmatizer.lemmatize(word) for word in clean_Tokens]\n",
        "\n",
        "print(lemma)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['one', 'best', 'movie', 'time', 'period']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rr4iL2yBoxp8",
        "colab_type": "text"
      },
      "source": [
        "####(5) POS Tagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enSDIKd6GxV-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "88973ba9-c5d5-42fb-c590-905320be7d86"
      },
      "source": [
        "pos_val = nltk.pos_tag(lemma)\n",
        "print(pos_val)\n",
        "\n",
        "pos=neg=obj=count=0"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('one', 'CD'), ('best', 'JJS'), ('movie', 'NN'), ('time', 'NN'), ('period', 'NN')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uggZN4TMvnDv",
        "colab_type": "text"
      },
      "source": [
        "#**Functions for Sentiment Scoring**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QsFpcxUKQZJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert between the PennTreebank tags to simple Wordnet tags\n",
        "def penn_to_wn(tag):\n",
        "    if tag.startswith('J'):\n",
        "        return wn.ADJ\n",
        "    elif tag.startswith('N'):\n",
        "        return wn.NOUN\n",
        "    elif tag.startswith('R'):\n",
        "        return wn.ADV\n",
        "    elif tag.startswith('V'):\n",
        "        return wn.VERB\n",
        "    return None"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpz9GfA3Kc22",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Returns list of pos-neg and objective score. But returns empty list if not present in senti wordnet.\n",
        "def get_sentiment(word,tag):\n",
        "    wn_tag = penn_to_wn(tag)\n",
        "    \n",
        "    if wn_tag not in (wn.NOUN, wn.ADJ, wn.ADV):\n",
        "        return []\n",
        "\n",
        "    #Lemmatization\n",
        "    lemma = lemmatizer.lemmatize(word, pos=wn_tag)\n",
        "    if not lemma:\n",
        "        return []\n",
        "\n",
        "    #Synset is a special kind of a simple interface that is present in NLTK to look up words in WordNet. \n",
        "    #Synset instances are the groupings of synonymous words that express the same concept. \n",
        "    #Some of the words have only one Synset and some have several.\n",
        "    synsets = wn.synsets(word, pos=wn_tag)\n",
        "    if not synsets:\n",
        "        return []\n",
        "\n",
        "    # Take the first sense, the most common\n",
        "    synset = synsets[0]\n",
        "    swn_synset = swn.senti_synset(synset.name())\n",
        "\n",
        "    return [synset.name(), swn_synset.pos_score(),swn_synset.neg_score(),swn_synset.obj_score()]"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7nuHaHLKjCH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3e190ca3-1ef8-4bad-ea0e-3e97cff3e174"
      },
      "source": [
        "senti_val = [get_sentiment(x,y) for (x,y) in pos_val]\n",
        "print(senti_val)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[], ['best.a.01', 0.75, 0.0, 0.25], ['movie.n.01', 0.0, 0.0, 1.0], ['time.n.01', 0.0, 0.0, 1.0], ['time_period.n.01', 0.125, 0.125, 0.75]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9iCiFBqvwKt",
        "colab_type": "text"
      },
      "source": [
        "#**Aggregating Scores**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdjCUMZuoS9l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(senti_val)):\n",
        "  try:\n",
        "    pos = pos + senti_val[i][1]\n",
        "    neg = neg + senti_val[i][2]\n",
        "    obj = obj + senti_val[i][3]\n",
        "  \n",
        "  except:\n",
        "    continue"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGefTwhdofsw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "611cbc5b-c9b9-487e-f049-bfe053a599fb"
      },
      "source": [
        "print(\"Positive weight : {0} \".format(pos))\n",
        "print(\"Negative weight : {0} \".format(neg))\n",
        "print(\"Sentiment of the statement is {0} \".format(pos - neg))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive weight : 0.875 \n",
            "Negative weight : 0.125 \n",
            "Sentiment of the statement is 0.75 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkYTwqFpShh5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 55,
      "outputs": []
    }
  ]
}